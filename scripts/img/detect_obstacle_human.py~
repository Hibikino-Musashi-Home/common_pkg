#!/usr/bin/env python
# -*- coding: utf-8 -*-


#--------------------------------------------------
#腕を振っている人を検出するプログラム
#
#Hibikino-Musashi@Home
#author: Yuta KIYAMA
#date: 16/03/09
#--------------------------------------------------

import rospy

import tf

import actionlib
from move_base_msgs.msg import MoveBaseAction
from move_base_msgs.msg import MoveBaseGoal

from std_msgs.msg import Float64
from geometry_msgs.msg import Twist

from geometry_msgs.msg import Pose
from geometry_msgs.msg import Point
from geometry_msgs.msg import Quaternion

from tf.transformations import quaternion_from_euler

import os
import sys
import math
import threading
import time

from subprocess import *

MAXID=5 #トラッキングする最大人数
DISTANCE_THERESHOLD=2.5 #判定距離
PI=3.1415
NUM_ANGLE_LOOP_MAX=180

#--------------------------------------------------
#--------------------------------------------------
def pubf_cmd_vel(linear_x, linear_y, linear_z, angular_x, angular_y, angular_z):
    pub_cmd_vel = rospy.Publisher('/cmd_vel', Twist, queue_size = 1)
    cmd_vel = Twist()
    cmd_vel.linear.x = linear_x
    cmd_vel.linear.y = linear_y
    cmd_vel.linear.z = linear_z
    cmd_vel.angular.x = angular_x
    cmd_vel.angular.y = angular_y
    cmd_vel.angular.z = angular_z
    pub_cmd_vel.publish(cmd_vel)
    print "cmd_vel"+str(angular_z)
#--------------------------------------------------
#--------------------------------------------------
def pubf_cam_pan(cam_pan_angle):
    pub_cam_pan_angle = rospy.Publisher('/dy_servo_cam_pan/angle', Float64, queue_size = 1)
    pub_cam_pan_angle.publish(cam_pan_angle)
    print "pan"+str(cam_pan_angle)

def actionf_move_base(x, y, yaw):
    move_base_action_client = actionlib.SimpleActionClient("move_base", MoveBaseAction)
    move_base_action_client.wait_for_server()

    quaternion = quaternion_from_euler(0.0, 0.0, yaw)        

    goal = MoveBaseGoal()
    goal.target_pose.header.frame_id = 'map'
    goal.target_pose.header.stamp = rospy.Time.now()
    goal.target_pose.pose = Pose(Point(x, y, 0), Quaternion(quaternion[0], quaternion[1], quaternion[2], quaternion[3]))
    move_base_action_client.send_goal(goal)

    #move_base_action_client.wait_for_result()
        
    call(['rosrun', 'common_pkg', 'slam_goto.py', str(x), str(y), str(yaw)])

    pubf_cmd_vel(0, 0, 0, 0, 0, 0)
 
    move_base_action_client.cancel_goal()
    print "x"+str(x)+" y"+str(y)+" yaw"+str(yaw) 

##------------------------------------------------
##------------------------------------------------
def cal_yaw(translationA,translationB):
   x1=translationA[0]
   y1=translationA[1]
   x2=translationB[0]
   y2=translationB[1]

   if x2-x1>=0 and y2-y1 >=0:
        return math.atan((y2-y1)/(x2-x1))
   if x2-x1<=0 and y2-y1 >=0:
        return math.atan((y2-y1)/(x2-x1))+(PI/4)*1
   if x2-x1<=0 and y2-y1 <=0:
        return math.atan((y2-y1)/(x2-x1))+(PI/4)*2
   if x2-x1>=0 and y2-y1 <0:
        return math.atan((y2-y1)/(x2-x1))+(PI/4)*3

##------------------------------------------------
##------------------------------------------------
def detectHumanInField(tf_head_translation):
    #パラメータサーバーからフィールドの範囲を取得
    #FIELD_MAX_X=n.getParam("/navigation/field/MAX_X");
    #FIELD_MIN_X=n.getParam("/navigation/field/MIN_X");
    #FIELD_MAX_Y=n.getParam("/navigation/field/MAX_Y");
    #FIELD_MIN_Y=n.getParam("/navigation/field/MIN_Y");
    FIELD_MAX_X=10
    FIELD_MIN_X=-10
    FIELD_MAX_Y=10
    FIELD_MIN_Y=-10
    print tf_head_translation[0]
    if tf_head_translation[0]<=FIELD_MAX_X and tf_head_translation[0]>=FIELD_MIN_X and tf_head_translation[1]<=FIELD_MAX_Y and tf_head_translation>=FIELD_MIN_Y:
        return 1
    else:
        return 0

class PanandMove_Thread():

    def __init__(self):
        self.stop_event=threading.Event()

        self.thread=threading.Thread(target=self.target)
        self.thread.start()

    def target(self):
        num_angle_loop=0
        while not self.stop_event.is_set():
            num_angle_loop+=1
            pubf_cam_pan(((num_angle_loop%90)-45)*PI/180)
            if num_angle_loop > NUM_ANGLE_LOOP_MAX:
                num_angle_loop=0 
            elif num_angle_loop == NUM_ANGLE_LOOP_MAX/4*1:
                pubf_cmd_vel(0,0,0,0,0,0.15)                
            elif num_angle_loop == NUM_ANGLE_LOOP_MAX/4*2:
                pubf_cmd_vel(0,0,0,0,0,-0.15)
            elif num_angle_loop == NUM_ANGLE_LOOP_MAX/4*3:
                pubf_cmd_vel(0,0,0,0,0,0.15)
            elif num_angle_loop == NUM_ANGLE_LOOP_MAX/4*4:
                pubf_cmd_vel(0,0,0,0,0,-0.15)
            time.sleep(0.1)

    def stop(self):
        self.stop_event.set()
        self.thread.join()

if __name__ == '__main__':
    
    node_name = os.path.basename(__file__)
    node_name = node_name.split('.')
    rospy.init_node(node_name[0])

    tf_listener=tf.TransformListener()

    tfTrackingId = 0
    Name_Tracking_head=""

    th=PanandMove_Thread();

    while not rospy.is_shutdown():
 
        if tfTrackingId <= MAXID:
            tfTrackingId+=1
            Name_Tracking_head="head_"+str(tfTrackingId)
        else:
            tfTrackingId=0
            Name_Tracking_head="head"
        
        try:
            (map2headtranslation,map2headrotation)=tf_listener.lookupTransform("map", Name_Tracking_head, rospy.Time(0))
            (camera2headtranslation,camera2headrotation)=tf_listener.lookupTransform("openni_depth_frame", Name_Tracking_head, rospy.Time(0))
        except:
            continue

        print 'hoge'

        if detectHumanInField(map2headtranslation):#フィールド内にいる人か
            #if camera2headtranslation[2]<=DISTANCE_THERESHOLD:#判定距離以内にいる人か
            print camera2headtranslation[0]
            if 1:
                #ここに検出時の処理を記述
                #人を見つけたら近づいて処理終了
                rospy.loginfo("DETECT_HUMAN "+str(tfTrackingId)) 
                th.stop()
                pubf_cam_pan(0)
                pubf_cmd_vel(0,0,0,0,0,0)
                (translation,rotation)=tf_listener.lookupTransform("map","base_link", rospy.Time(0))
                while ((translation[0]-map2headtranslation[0])*(translation[0]-map2headtranslation[0])+(translation[1]-map2headtranslation[1])*(translation[1]-map2headtranslation[1]))>=1:
                    try:
                        (translation,rotation)=tf_listener.lookupTransform("map","base_link", rospy.Time(0))
                        (map2headtranslation,map2headrotation)=tf_listener.lookupTransform("map",Name_Tracking_head, rospy.Time(0))
                    except:
                        continue
                    actionf_move_base((translation[0]+map2headtranslation[0])/2, (translation[1]+map2headtranslation[1])/2,cal_yaw(translation,map2headtranslation))
                
                pubf_cmd_vel(0,0,0,0,0,0)
                sys.exit(0)
    th.stop()

