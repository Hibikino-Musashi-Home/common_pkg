#!/usr/bin/env python
# -*- coding: utf-8 -*-


#--------------------------------------------------
#腕を振っている人を検出するプログラム
#
#Hibikino-Musashi@Home
#author: Yuta KIYAMA
#date: 16/03/05 
#--------------------------------------------------

import rospy

import tf

import actionlib

from std_msgs.msg import Float64
from geometry_msgs.msg import Twist

import os
import sys

from common_pkg.msg import CamLiftAction
from common_pkg.msg import CamLiftGoal


MAXID=5 #トラッキングする最大人数
DISTANCE_THERESHOLD=1.0 #判定距離 
ANGLE_LOOP_MAX=10000
PI=3.1415

#--------------------------------------------------
#--------------------------------------------------
def pubf_cmd_vel(linear_x, linear_y, linear_z, angular_x, angular_y, angular_z):
    pub_cmd_vel = rospy.Publisher('/cmd_vel', Twist, queue_size = 1)
    cmd_vel = Twist()
    cmd_vel.linear.x = linear_x
    cmd_vel.linear.y = linear_y
    cmd_vel.linear.z = linear_z
    cmd_vel.angular.x = angular_x
    cmd_vel.angular.y = angular_y
    cmd_vel.angular.z = angular_z
    pub_cmd_vel.publish(cmd_vel)
    rospy.sleep(0.5)
    pub_cmd_vel.publish(cmd_vel)

#--------------------------------------------------
#--------------------------------------------------
def pubf_cam_pan(cam_pan_angle):
    pub_cam_pan_angle = rospy.Publisher('/dy_servo_cam_pan/angle', Float64, queue_size = 1)
    pub_cam_pan_angle.publish(cam_pan_angle)

##------------------------------------------------
##------------------------------------------------
def detectHumanInField(tf_head_translation):
    #パラメータサーバーからフィールドの範囲を取得
    #FIELD_MAX_X=n.getParam("/navigation/field/MAX_X");
    #FIELD_MIN_X=n.getParam("/navigation/field/MIN_X");
    #FIELD_MAX_Y=n.getParam("/navigation/field/MAX_Y");
    #FIELD_MIN_Y=n.getParam("/navigation/field/MIN_Y");
    FIELD_MAX_X=10
    FIELD_MIN_X=0
    FIELD_MAX_Y=10
    FIELD_MIN_Y=0
   
    if tf_head_translation[0]<=FIELD_MAX_X and tf_head_translation[0]>=FIELD_MIN_X and tf_head_translation[1]<=FIELD_MAX_Y and tf_head_translation>=FIELD_MIN_Y:
        return 1
    else:
        return 0


if __name__ == '__main__':
    
    node_name = os.path.basename(__file__)
    node_name = node_name.split('.')
    rospy.init_node(node_name[0])

    tf_listener=tf.TransformListener()

    tfTrackingId = 0
    Name_Tracking_head=""
    num_angle_loop = 0
    num_angle_a= 0
    pubf_cmd_vel(0,0,0,0,0,-0.15)
    while not rospy.is_shutdown():

        num_angle_loop+=1

        if num_angle_loop >= ANGLE_LOOP_MAX:
            num_angle_loop=0
            num_angle_a+=1
            pubf_cam_pan(((num_angle_a%90)-45)*PI/180)
            if num_angle_a > 101:
                num_angle_a=0 
            elif num_angle_a == 25:
                pubf_cmd_vel(0,0,0,0,0,0.15)                
            elif num_angle_a == 50:
                pubf_cmd_vel(0,0,0,0,0,-0.15)
            elif num_angle_a == 75:
                pubf_cmd_vel(0,0,0,0,0,0.15)
            elif num_angle_a == 100:
                pubf_cmd_vel(0,0,0,0,0,-0.15)
                
 
        if tfTrackingId <= MAXID:
            tfTrackingId+=1
            Name_Tracking_head="head_"+str(tfTrackingId)
        else:
            tfTrackingId=0
            Name_Tracking_head="head"



        try:
            (map2translation,map2rotation)=tf_listener.lookupTransform("map", Name_Tracking_head, rospy.Time(0))
            (camera2translation,camera2rotation)=tf_listener.lookupTransform("openni_depth_frame", Name_Tracking_head, rospy.Time(0))
        except:
            continue

        if detectHumanInField(map2translation):#フィールド内にいる人か
            if camera2translation[2]<=DISTANCE_THERESHOLD:#判定距離以内にいる人か
                #ここに検出時の処理を記述
                #人を見つけたら処理終了
                rospy.loginfo("DETECT_HUMAN "+src(tfTrackingId)) 

