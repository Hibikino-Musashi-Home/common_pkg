//--------------------------------------------------
//オブジェクト検出・認識ROS
//
//author: Yutaro ISHIDA
//date: 16/03/08
//
//TODO: パラメータを定数化する
//TODO: オブジェクトのtfに回転を与える
//--------------------------------------------------


#include <common_pkg/common_include.h>
#include <common_pkg/common_function.h>


//pcl::visualization::CloudViewer viewer("viewer");


//--------------------------------------------------
//オブジェクト検出・認識クラス
//--------------------------------------------------
class ObjProc{
private:
    //ROSノードのハンドル
    ros::NodeHandle nh_;

    int dbg_sm_flow_;
    int dbg_speech_onlyspeech_;
    double iarm_obj_height_;

    image_transport::ImageTransport img_t_;
    image_transport::Subscriber img_sub_smi_cam_;
    image_transport::Publisher img_pub_smi_obj_;

    ros::Subscriber sub_smpc_cam_;
    ros::Publisher pub_smpc_plane_;
    ros::Publisher pub_smpc_pt_;
    ros::Publisher pub_smpc_objs_;

    actionlib::SimpleActionClient<common_pkg::ObjRecAction> obj_rec_action_;    

    cv::Mat rgb_cvimg_;
    
    int sub_smpc_cam_cnt_;

    //オブジェクト認識の投票用変数
    //同オブジェクト位置でもオブジェクト番号が異なったら、異なるキー番号で保存される
    //同オブジェクト番号でもオブジェクト位置が異なったら、異なるキー番号で保存される
    //例: 1個目のオブジェクト(キー番号: 0)
    //オブジェクト位置 objs_pos_[0].x = [m], objs_pos_[0].y = [m], objs_pos_[0].z = [m]
    //投票数 objs_poll_[0] = 1～5?
    vector< vector<float> > objs_pos_; //オブジェクト位置
    vector<int> objs_poll_; //投票数

    CommonFunction* CommonFunction_;


public:
    //--------------------------------------------------
    //コンストラクタ
    //--------------------------------------------------
    ObjProc():img_t_(nh_), obj_rec_action_("obj_rec_action", true){
        nh_.getParam("/param/dbg/sm/flow", dbg_sm_flow_);
        nh_.getParam("/param/dbg/speech/onlyspeech", dbg_speech_onlyspeech_);
        if(dbg_sm_flow_ == 1 || dbg_speech_onlyspeech_ == 1){
            exit(0);
        }

        nh_.getParam("/param/iarm/obj/height", iarm_obj_height_);

        img_sub_smi_cam_ = img_t_.subscribe("/camera/rgb/image_raw", 1, &ObjProc::subf_smi_cam, this);
        img_pub_smi_obj_ = img_t_.advertise("/obj_proc/img/obj", 1);

        sub_smpc_cam_ = nh_.subscribe("/camera/depth_registered/points", 1, &ObjProc::subf_smpc_cam, this);
        pub_smpc_pt_ = nh_.advertise<sensor_msgs::PointCloud2>("/obj_proc/pc/pt", 1);         
        pub_smpc_plane_ = nh_.advertise<sensor_msgs::PointCloud2>("/obj_proc/pc/plane", 1);
        pub_smpc_objs_ = nh_.advertise<sensor_msgs::PointCloud2>("/obj_proc/pc/objs", 1);

        obj_rec_action_.waitForServer();
      
        sub_smpc_cam_cnt_ = 0;

        CommonFunction_ = new CommonFunction(nh_);

        CommonFunction_->commonf_actionf_speech_multi(nh_, "オブジェクトを探します。");

        CommonFunction_->commonf_actionf_cam_lift(nh_, iarm_obj_height_ - 0.18); //-0.28
        CommonFunction_->commonf_pubf_cam_tilt(nh_, 0.785);

        ros::Duration(2).sleep();
    }


    //--------------------------------------------------
    //デストラクタ
    //--------------------------------------------------
    ~ObjProc(){
    }


    //--------------------------------------------------
    //カラーイメージSubscribe関数
    //--------------------------------------------------
    void subf_smi_cam(const sensor_msgs::ImageConstPtr& i_smi){
        cv_bridge::CvImagePtr cv_img_ptr;
        cv_img_ptr = cv_bridge::toCvCopy(i_smi, sensor_msgs::image_encodings::BGR8);
        rgb_cvimg_ = cv_img_ptr->image;
    }


    //--------------------------------------------------
    //ポイントクラウドSubscribe関数
    //--------------------------------------------------
    void subf_smpc_cam(const sensor_msgs::PointCloud2ConstPtr& i_smpc_ptr){ //smpc_ptr: sensor_msgs::PointCloud2ConstPtr&
          //複数箇所でオブジェクトをカウントする
        //sub_smpc_cam_cnt_++;
        if(sub_smpc_cam_cnt_ == 6 || sub_smpc_cam_cnt_ == 12|| sub_smpc_cam_cnt_ == 18 || sub_smpc_cam_cnt_ == 24){
            //CommonFunction_->commonf_actionf_speech_multi(nh_, "２０センチ横に移動します。");
            //CommonFunction_->commonf_pubf_cmd_vel(nh_, 0, -0.2, 0, 0, 0, 0);
            //ros::Duration(1.5).sleep();
            //CommonFunction_->commonf_pubf_cmd_vel(nh_, 0, 0, 0, 0, 0, 0);
            //ros::Duration(2).sleep();
            //CommonFunction_->commonf_actionf_speech_multi(nh_, "もう一度探します。"); //New
            return;
        }
        else if(sub_smpc_cam_cnt_ == 30){
            //CommonFunction_->commonf_actionf_speech_single(nh_, "オブジェクトがありませんでした。");
            //CommonFunction_->commonf_actionf_speech_multi(nh_, "８０センチ横に移動します。");
            CommonFunction_->commonf_pubf_cmd_vel(nh_, 0, 0.2, 0, 0, 0, 0);
            ros::Duration(4.5).sleep();
            CommonFunction_->commonf_pubf_cmd_vel(nh_, 0, 0, 0, 0, 0, 0);
            ros::Duration(2).sleep();
            exit(1);
        }


        //sensor_msgs::PointCloud2ConstPtr&からpcl::PointCloud<pcl::PointXYZRGB>に変換
        pcl::PointCloud<pcl::PointXYZRGB> i_pc; //pc: PointCloud<>
        pcl::fromROSMsg (*i_smpc_ptr, i_pc);

        pcl::PointCloud<pcl::PointXYZRGB>::Ptr i_pc_ptr(new pcl::PointCloud<pcl::PointXYZRGB>(i_pc)); //pc_ptr: PointCloud<>::Ptr

        pcl::PointCloud<pcl::PointXYZRGB>::Ptr plane_pc_ptr(new pcl::PointCloud<pcl::PointXYZRGB>);
        pcl::PointCloud<pcl::PointXYZRGB>::Ptr objs_pc_ptr(new pcl::PointCloud<pcl::PointXYZRGB>);

        
        //viewer.showCloud(_pc_ptr); //何故かThinkPad T450では動かない


        //ダウンサンプリング
        pcl::VoxelGrid<pcl::PointXYZRGB> vg;
        vg.setInputCloud(i_pc_ptr);
        vg.setLeafSize(0.01, 0.01, 0.01); //ダウンサンプリングの間隔[m]
        vg.filter(*plane_pc_ptr);


        //パススルーフィルタでポイントクラウドの領域を制限
        pcl::PassThrough<pcl::PointXYZRGB> pass_th;

        pass_th.setInputCloud(plane_pc_ptr);
        pass_th.setFilterFieldName("x");
        pass_th.setFilterLimits(-0.1, 0.3);
        pass_th.setFilterLimitsNegative(false);
        pass_th.filter(*plane_pc_ptr);

        pass_th.setInputCloud(plane_pc_ptr);
        pass_th.setFilterFieldName("y");
        pass_th.setFilterLimits(-0.15, 0.2);
        pass_th.setFilterLimitsNegative(false);
        pass_th.filter(*plane_pc_ptr);

        pass_th.setInputCloud(plane_pc_ptr);
        pass_th.setFilterFieldName("z");
        pass_th.setFilterLimits(0.4, 0.8);
        pass_th.setFilterLimitsNegative(false);
        pass_th.filter(*plane_pc_ptr);

        //パススルーフィルタを通したポイントクラウドをPublish
        sensor_msgs::PointCloud2 o_smpc_pt;
        pcl::toROSMsg(*plane_pc_ptr, o_smpc_pt);
        o_smpc_pt.header.frame_id = "camera_depth_optical_frame";
        pub_smpc_pt_.publish(o_smpc_pt);


        //ポイントクラウドをコピー
        pcl::copyPointCloud<pcl::PointXYZRGB, pcl::PointXYZRGB>(*plane_pc_ptr, *objs_pc_ptr);  


        //平面検出
        pcl::ModelCoefficients::Ptr model_coef(new pcl::ModelCoefficients);
        pcl::PointIndices::Ptr indices(new pcl::PointIndices);

        //セグメンテーションオブジェクト生成
        pcl::SACSegmentation<pcl::PointXYZRGB> sac_seg;
        //セグメンテーションオブジェクト必須オプション指定
        sac_seg.setModelType(pcl::SACMODEL_PLANE);
        sac_seg.setMethodType(pcl::SAC_RANSAC);
        sac_seg.setDistanceThreshold(0.01); //[m]
        //セグメンテーションオブジェクトオプション指定
        sac_seg.setOptimizeCoefficients(true);
        //セグメンテーションオブジェクトにポイントクラウドを入力して平面検出
        sac_seg.setInputCloud(objs_pc_ptr);
        sac_seg.segment (*indices, *model_coef);

        //平面が検出されない場合
        if(indices->indices.size() == 0){
            ROS_INFO("[obj_proc]: There is no plane.");
            return;
        }

        //平面を青色にする
        for(size_t i = 0; i < indices->indices.size(); ++i){
            plane_pc_ptr->points[indices->indices[i]].r = 0;
            plane_pc_ptr->points[indices->indices[i]].g = 0;
            plane_pc_ptr->points[indices->indices[i]].b = 255;
        }

        //平面を青色にしたポイントクラウドをパブリッシュ
        sensor_msgs::PointCloud2 o_smpc_plane;
        pcl::toROSMsg(*plane_pc_ptr, o_smpc_plane);
        o_smpc_plane.header.frame_id = "camera_depth_optical_frame";
        pub_smpc_plane_.publish(o_smpc_plane);


        //平面除去
        pcl::ExtractIndices<pcl::PointXYZRGB> ext;
        ext.setInputCloud(objs_pc_ptr);
        ext.setIndices(indices);
        ext.setNegative(true); //trueにすると平面を除去、falseにすると平面以外を除去
        ext.filter(*objs_pc_ptr);

        //複数のオブジェクトが含まれたポイントクラウドをパブリッシュ
        sensor_msgs::PointCloud2 o_smpc_objs;
        pcl::toROSMsg(*objs_pc_ptr, o_smpc_objs);
        o_smpc_objs.header.frame_id = "camera_depth_optical_frame";
        pub_smpc_objs_.publish(o_smpc_objs);


        //クラスタリング
        pcl::search::KdTree<pcl::PointXYZRGB>::Ptr kdtree(new pcl::search::KdTree<pcl::PointXYZRGB>);
        kdtree->setInputCloud(objs_pc_ptr);

        std::vector<pcl::PointIndices> cluster_indices; //クラスター情報

        pcl::EuclideanClusterExtraction<pcl::PointXYZRGB> ec_ext;
        ec_ext.setClusterTolerance(0.2); //クラスターを分ける閾値[m]
        ec_ext.setMinClusterSize(100); //最小のクラスターの値を設定
        ec_ext.setMaxClusterSize(1000); //最大のクラスターの値を設定
        ec_ext.setSearchMethod(kdtree); //検索に使用する手法を指定
        ec_ext.setInputCloud(objs_pc_ptr); //点群を入力
        ec_ext.extract(cluster_indices); //クラスター情報を出力


        //クラスタを1塊ごとに出力
        for(std::vector<pcl::PointIndices>::const_iterator it1 = cluster_indices.begin(); it1 != cluster_indices.end(); ++it1){
            //オブジェクトの各座標における最小、最大値
            double obj_pc_x_min = objs_pc_ptr->points[*it1->indices.begin()].x;
            double obj_pc_x_max = objs_pc_ptr->points[*it1->indices.begin()].x;
            double obj_pc_y_min = objs_pc_ptr->points[*it1->indices.begin()].y;
            double obj_pc_y_max = objs_pc_ptr->points[*it1->indices.begin()].y;
            double obj_pc_z_min = objs_pc_ptr->points[*it1->indices.begin()].z;
            double obj_pc_z_max = objs_pc_ptr->points[*it1->indices.begin()].z;
        
            for(std::vector<int>::const_iterator it2 = it1->indices.begin(); it2 != it1->indices.end(); it2++){
                if(obj_pc_x_min > objs_pc_ptr->points[*it2].x) obj_pc_x_min = objs_pc_ptr->points[*it2].x;
                if(obj_pc_x_max < objs_pc_ptr->points[*it2].x) obj_pc_x_max = objs_pc_ptr->points[*it2].x;
                if(obj_pc_y_min > objs_pc_ptr->points[*it2].y) obj_pc_y_min = objs_pc_ptr->points[*it2].y;
                if(obj_pc_y_max < objs_pc_ptr->points[*it2].y) obj_pc_y_max = objs_pc_ptr->points[*it2].y;
                if(obj_pc_z_min > objs_pc_ptr->points[*it2].z) obj_pc_z_min = objs_pc_ptr->points[*it2].z;
                if(obj_pc_z_max < objs_pc_ptr->points[*it2].z) obj_pc_z_max = objs_pc_ptr->points[*it2].z;            
            }

            //オブジェクトの角座標における中心座標
            double obj_pc_x_ave = (obj_pc_x_min + obj_pc_x_max) / 2.0;
            double obj_pc_y_ave = (obj_pc_y_min + obj_pc_y_max) / 2.0;
            double obj_pc_z_ave = (obj_pc_z_min + obj_pc_z_max) / 2.0;


            pcl::PointCloud<pcl::PointXYZRGB>::Ptr obj_pc_ptr(new pcl::PointCloud<pcl::PointXYZRGB>(i_pc));

            //オブジェクトとそれ以外の領域でポイントクラウドの色を変える
            for(size_t i = 0; i < obj_pc_ptr->points.size(); ++i){
                if(obj_pc_x_min < obj_pc_ptr->points[i].x &&
                   obj_pc_x_max > obj_pc_ptr->points[i].x &&
                   obj_pc_y_min < obj_pc_ptr->points[i].y &&
                   obj_pc_y_max > obj_pc_ptr->points[i].y &&
                   obj_pc_y_max < obj_pc_ptr->points[i].z &&
                   obj_pc_z_max > obj_pc_ptr->points[i].z){
                    //オブジェクト(カラーのまま)
                    //obj_pc_ptr->points[i].r = 255;
                    //obj_pc_ptr->points[i].g = 255;
                    //obj_pc_ptr->points[i].b = 255;
                }
                else{
                    //オブジェクト以外(黒)
                    obj_pc_ptr->points[i].r = 0;
                    obj_pc_ptr->points[i].g = 0;
                    obj_pc_ptr->points[i].b = 0;
                }               
            }


            //オブジェクトを抽出したイメージを生成
            sensor_msgs::PointCloud2 o_smpc_obj;
            pcl::toROSMsg(*obj_pc_ptr, o_smpc_obj);
            o_smpc_obj.header.frame_id = "camera_depth_optical_frame";
            sensor_msgs::Image obj_smi;
            pcl::toROSMsg(o_smpc_obj, obj_smi);

            
            cv_bridge::CvImagePtr cv_img_ptr;
            cv_img_ptr = cv_bridge::toCvCopy(obj_smi, sensor_msgs::image_encodings::BGR8);

            cv::Mat obj_cvimg;
            obj_cvimg = cv_img_ptr->image;


            vector<cv::Point2i> points_v;
            cv::Point2i obj_center(0, 0);

            //オブジェクトの座標をvector<cv::Point2i>に詰める
            for(int y = 0; y < obj_cvimg.rows; y = y + 5){
                for(int x = 0; x < obj_cvimg.cols; x = x + 5){
                    if(obj_cvimg.at<cv::Vec3b>(y, x)[0] != 0 && //[0]:B [1]:G [2]:R
                       obj_cvimg.at<cv::Vec3b>(y, x)[1] != 0 &&
                       obj_cvimg.at<cv::Vec3b>(y, x)[2] != 0){
                        points_v.push_back(cv::Point2i(x, y));
                        obj_center.x += x;
                        obj_center.y += y;
                    }
                }
            }
       
            //オブジェクトの中心座標を算出
            if((int)points_v.size() != 0){ //0除算防止
                obj_center.x = obj_center.x / (int)points_v.size();
                obj_center.y = obj_center.y / (int)points_v.size();
            }
/*
            cv::Mat points_m(points_v);
            
            //オブジェクトを囲む回転有矩形を算出
            cv::RotatedRect rrect = cv::minAreaRect(cv::Mat(points_m).reshape(2));

            //イメージ左側の回転角度を算出
            if(rrect.angle >= -45){
                //rrect.angle = rrect.angle;
            }
            //イメージ右側の回転角度を算出
            else{
                rrect.angle = rrect.angle + 90;
            }

            //オブジェクトを中心としたイメージ回転行列を算出
            cv::Mat matrix = cv::getRotationMatrix2D(obj_center, rrect.angle, 1);

            //オブジェクトを抽出したイメージ、カラーイメージを回転
            cv::Mat obj_cvimg_rot;
            cv::warpAffine(obj_cvimg, obj_cvimg_rot, matrix, obj_cvimg.size());            
            cv::Mat rgb_cvimg_rot;
            cv::warpAffine(rgb_cvimg_, rgb_cvimg_rot, matrix, rgb_cvimg_.size());


            //オブジェクトの各座標における最小、最大値
            int obj_cvimg_y_min = obj_cvimg_rot.rows;
            int obj_cvimg_y_max = 0;
            int obj_cvimg_x_min = obj_cvimg_rot.cols;
            int obj_cvimg_x_max = 0;
            
            for(int y = 0; y < obj_cvimg_rot.rows; y++){
                for(int x = 0; x < obj_cvimg_rot.cols; x++){
                    if(obj_cvimg_rot.at<cv::Vec3b>(y, x)[0] != 0 &&
                       obj_cvimg_rot.at<cv::Vec3b>(y, x)[1] != 0 &&
                       obj_cvimg_rot.at<cv::Vec3b>(y, x)[2] != 0){
                        if(obj_cvimg_y_min > y) obj_cvimg_y_min = y;
                        if(obj_cvimg_y_max < y) obj_cvimg_y_max = y;
                        if(obj_cvimg_x_min > x) obj_cvimg_x_min = x;
                        if(obj_cvimg_x_max < x) obj_cvimg_x_max = x;
                    }
                    //オブジェクト以外の領域のカラーイメージを黒にする
                    //else{
                    //    rgb_img_rot.at<cv::Vec3b>(y, x)[0] = 0;
                    //    rgb_img_rot.at<cv::Vec3b>(y, x)[1] = 0;
                    //    rgb_img_rot.at<cv::Vec3b>(y, x)[2] = 0;
                    //}                   
                }
            }


               //学習・識別用オブジェクトイメージを生成
            cv::Mat roi_cvimg = rgb_cvimg_rot(cv::Rect(obj_cvimg_x_min, obj_cvimg_y_min, obj_cvimg_x_max - obj_cvimg_x_min, obj_cvimg_y_max - obj_cvimg_y_min));


               //学習・識別用オブジェクトイメージをPublish
            cv_img_ptr->image = roi_cvimg;
            img_pub_smi_obj_.publish(cv_img_ptr->toImageMsg());


            cv_bridge::CvImage cv_img;
            cv_img.image = roi_cvimg; 
            sensor_msgs::Image roi_smimg;
            cv_img.toImageMsg(roi_smimg);


               //オブジェクト学習・認識ノードにActionを介してオブジェクトイメージを送信
            common_pkg::ObjRecGoal goal;
            goal.obj_rec_goal = roi_smimg;
            obj_rec_action_.sendGoal(goal);

               //オブジェクト学習・認識ノードの結果を待つ
            obj_rec_action_.waitForResult();

               //オブジェクト学習・認識ノードの結果を受信
            int obj_rec_result = obj_rec_action_.getResult()->obj_rec_result;
*/
            int obj_rec_result = 3;

            int iarm_obj_id;
            nh_.getParam("/param/iarm/obj/id", iarm_obj_id);
            if(obj_rec_result == iarm_obj_id){
                printf("hogehoge\n");
                tf::TransformListener tf_listener;
                tf::StampedTransform tf_stamped_transform;

                tf::TransformBroadcaster tf_broadcaster;
                tf::Transform tf_transform;
                tf_transform.setOrigin(tf::Vector3(obj_pc_x_ave , obj_pc_y_ave, obj_pc_z_ave));
                tf::Quaternion tf_quaternion;
                tf_quaternion.setRPY(0, 0, 0);
                tf_transform.setRotation(tf_quaternion);

                while(ros::ok()){
                    tf_broadcaster.sendTransform(tf::StampedTransform(tf_transform, ros::Time::now(), "camera_depth_optical_frame", "obj"));
                    try{
                        tf_listener.lookupTransform("base_link", "obj", ros::Time(0), tf_stamped_transform);
                    }
                    catch(tf::TransformException){
                        continue;
                    }
                    break;
                }


                //オブジェクト学習・認識ノードの結果を投票
                bool flag_poll = false; //投票が行われたかチェックするフラグ
                for(size_t i = 0; i < objs_pos_.size(); i++){
                    //ほぼ同じ座標か確認
                    if(abs(objs_pos_[i][0] - tf_stamped_transform.getOrigin().x()) < 0.1 &&
                       abs(objs_pos_[i][1] - tf_stamped_transform.getOrigin().y()) < 0.1 &&
                       abs(objs_pos_[i][2] - tf_stamped_transform.getOrigin().z()) < 0.1){
                        objs_poll_[i]++;
                        flag_poll = true;

                        //3回以上投票された場合
                        if(objs_poll_[i] >= 3){
                            CommonFunction_->commonf_actionf_speech_single(nh_, "オブジェクトを発見しました。");

                            nh_.setParam("/param/iarm/obj/pos/x", tf_stamped_transform.getOrigin().x());
                            nh_.setParam("/param/iarm/obj/pos/y", tf_stamped_transform.getOrigin().y());
                            nh_.setParam("/param/iarm/obj/pos/z", iarm_obj_height_ + 0.05); //tf_stamped_transform.getOrigin().z());                            
                              
                            exit(0);
                        }
                    }
                }

                //投票されなかった時、新規投票
                if(flag_poll == false){
/*
                    vector<float> buf_pos(3);
                    buf_pos[0] = tf_stamped_transform.getOrigin().x();
                    buf_pos[1] = tf_stamped_transform.getOrigin().y();
                    buf_pos[2] = tf_stamped_transform.getOrigin().z();
                    objs_pos_.push_back(buf_pos);
                    objs_poll_.push_back(1);
*/
                            CommonFunction_->commonf_actionf_speech_single(nh_, "オブジェクトを発見しました。");

                            nh_.setParam("/param/iarm/obj/pos/x", tf_stamped_transform.getOrigin().x());
                            nh_.setParam("/param/iarm/obj/pos/y", tf_stamped_transform.getOrigin().y());
                            nh_.setParam("/param/iarm/obj/pos/z", iarm_obj_height_ + 0.05); //tf_stamped_transform.getOrigin().z());                            
                              
                            exit(0);
                }
            }


/*
            for(int y = 0; y < obj_img.rows; y++){
                for(int x = 0; x < obj_img.cols; x++){
                    if((obj_img_y_min == y || obj_img_y_max == y) && (obj_img_x_min <= x && obj_img_x_max >= x)){
                        obj_img_rot.at<cv::Vec3b>(y, x)[0] = 255;
                        obj_img_rot.at<cv::Vec3b>(y, x)[1] = 255;
                        obj_img_rot.at<cv::Vec3b>(y, x)[2] = 255;

                        rgb_img_rot.at<cv::Vec3b>(y, x)[0] = 255;
                        rgb_img_rot.at<cv::Vec3b>(y, x)[1] = 255;
                        rgb_img_rot.at<cv::Vec3b>(y, x)[2] = 255;
                    }
                    if((obj_img_x_min == x || obj_img_x_max == x) && (obj_img_y_min <= y && obj_img_y_max >= y)){
                        obj_img_rot.at<cv::Vec3b>(y, x)[0] = 255;
                        obj_img_rot.at<cv::Vec3b>(y, x)[1] = 255;
                        obj_img_rot.at<cv::Vec3b>(y, x)[2] = 255;

                        rgb_img_rot.at<cv::Vec3b>(y, x)[0] = 255;
                        rgb_img_rot.at<cv::Vec3b>(y, x)[1] = 255;
                        rgb_img_rot.at<cv::Vec3b>(y, x)[2] = 255;
                    }                   
                }
            }

            cv::imshow("Img1", obj_img);
            cv::imshow("Img2", obj_img_rot);
            cv::imshow("Img3", rgb_img_rot);
            cv::imshow("Img4", roi_img);
            cvWaitKey(0);
*/
        }
    }
};


//--------------------------------------------------
//メイン関数
//--------------------------------------------------
int main (int argc, char** argv){
    ros::init (argc, argv, "obj_proc");

    ObjProc ObjProc;

    while(ros::ok()){
        ros::spinOnce(); 
    }
}
